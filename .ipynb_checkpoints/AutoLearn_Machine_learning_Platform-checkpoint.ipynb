{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myYx1l-Ultf-"
   },
   "source": [
    "# **Auto Learn**\n",
    "\n",
    "I started this project to showcase a simple way for beginner data scientists to create machine learning models and data visualizations automatically without having to scratch their heads for large amounts of time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing All the necessary Libraries to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:32:59.178785Z",
     "start_time": "2021-06-26T10:32:53.809911Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsdfCOmFm-Hg",
    "outputId": "b9314a4e-b22c-4379-ff58-c064ab62f912",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n"
     ]
    }
   ],
   "source": [
    "#Importing all the needed Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#This notebook is running a version of plotly version 4.14.3.\n",
    "## Make sure you have this version installed to have it working nicely\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "print(plotly.__version__)\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 6\n",
    "plt.rcParams['xtick.labelsize']= 10\n",
    "plt.rcParams['ytick.labelsize']= 10\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T08:48:29.345818Z",
     "start_time": "2021-05-24T08:48:29.324872Z"
    },
    "code_folding": [
     0,
     2,
     6,
     22,
     38
    ]
   },
   "outputs": [],
   "source": [
    "class Data_Quality_Report(object):\n",
    "    \n",
    "    def __init__(self, data, threshold):\n",
    "        self.threshold = threshold\n",
    "        self.data= data\n",
    "        \n",
    "    def Categorical_Detector(self):\n",
    "        df= self.data.copy()\n",
    "        category_features = []\n",
    "        for name in self.data.columns.to_list():\n",
    "            if df[name].nunique() <= self.threshold:\n",
    "                    category_features.append(name)\n",
    "            \n",
    "            elif self.data[name].dtype== 'object':\n",
    "                    category_features.append(name)\n",
    "            \n",
    "        dataframe= []\n",
    "        for each in category_features:\n",
    "            df[each] = df[each].astype('category')\n",
    "\n",
    "        return df\n",
    "        \n",
    "    def OUTLIER_DETECTOR(self):\n",
    "        data= self.data\n",
    "        df= data.select_dtypes(include= ['float64', 'int64'])\n",
    "        columns= df.columns.to_list()\n",
    "        frame= pd.DataFrame([])\n",
    "        for name in columns:\n",
    "            frequency= data[data[name]== data[name].mode()[0]][name].count()\n",
    "            common_value= data[name].mode()[0].astype('int64')\n",
    "            unique= df[name].nunique()\n",
    "            Q1 = df[name].quantile(0.25)\n",
    "            Q3 = df[name].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            num_outliers= ((df[name] < (Q1 - 1.5 * IQR)) | (df[name] > (Q3 + 1.5 * IQR))).sum().astype('int64')\n",
    "            frame= frame.append(pd.DataFrame({'Feature name': [name],'Unique': [unique], 'Outliers': [num_outliers], 'Common_value': [common_value], 'Frequency': [frequency]}))\n",
    "        return frame\n",
    "\n",
    "    def QUALITY_DATA_ASSESSMENT(self):\n",
    "        data= self.data\n",
    "        data= self.Categorical_Detector()\n",
    "    \n",
    "        df= data.describe(include= 'all').T\n",
    "        df= df.reset_index()\n",
    "        df['Variable type']= df['index'].apply(lambda x: data[x].dtype)\n",
    "        df['Missing']= df['index'].apply(lambda x: data[x].isnull().sum())\n",
    "        df['Missing Percentage']= df['Missing'].apply(lambda x: round(x/len(data)*100,2))\n",
    "        df= df.reset_index()\n",
    "        df.columns= ['Index','Feature name', 'Records', 'unique', 'Commom Value', 'frequency', 'Mean', 'Std Dev', 'Minimum', '25th Quartile', 'Median', '75th Quartile', 'Maximum', 'Variable type', 'Missing', 'Missing Percentage']\n",
    "        \n",
    "        df1= self.OUTLIER_DETECTOR()\n",
    "        frame= pd.merge(df,df1, how= 'left', on= 'Feature name')\n",
    "    \n",
    "        frame= frame[['Feature name','Index','Variable type','Records', 'Unique', 'Missing','Missing Percentage',\n",
    "                  'Common_value', 'Frequency', 'Outliers', 'Mean', 'Std Dev', 'Minimum', '25th Quartile',\n",
    "                  'Median', '75th Quartile', 'Maximum']]\n",
    "\n",
    "        frame= frame.sort_values(by=['Unique'], ascending= False)\n",
    "    \n",
    "    \n",
    "        cat_data= frame[frame['Variable type'] == 'category']\n",
    "        num_data= frame[frame['Variable type'] != 'category']\n",
    "    \n",
    "        categorical= data[cat_data['Feature name'].to_list()].describe(include= 'all').T\n",
    "        categorical.reset_index(inplace= True)\n",
    "    \n",
    "        categorical['Var type']= categorical['index'].apply(lambda x: data[x].dtype)\n",
    "        categorical['Missing']= categorical['index'].apply(lambda x: data[x].isnull().sum())\n",
    "        categorical['Missing Percentage']= categorical['Missing'].apply(lambda x: round(x/len(data)*100,2))\n",
    "        categorical.reset_index(inplace= True)\n",
    "    \n",
    "        categorical.columns= ['Index','Feature name','Records', 'Unique','Common_value', 'Frequency', 'Variable type','Missing', 'Missing Percentage']\n",
    "        categorical= categorical[['Feature name','Index', 'Variable type','Records', 'Unique','Missing', 'Missing Percentage','Common_value', 'Frequency']]\n",
    "        categorical.sort_values(by= ['Missing'])\n",
    "    \n",
    "        final= num_data.append(categorical, sort= True)\n",
    "        final.sort_values(by= ['Unique'], ascending= False)\n",
    "        final.replace(np.NaN,'*', inplace=True)\n",
    "        \n",
    "        final= final[['Feature name','Variable type','Records', 'Unique', 'Missing','Missing Percentage',\n",
    "                  'Common_value', 'Frequency', 'Outliers', 'Mean', 'Std Dev', 'Minimum', '25th Quartile',\n",
    "                  'Median', '75th Quartile', 'Maximum']]\n",
    "                \n",
    "        name= \"*\"\n",
    "        print(f\" Note that {name} indicate that no calculation record can be found for that field\")\n",
    "        return final\n",
    "    \n",
    "    def Impute_Missing_data(self, path= None):\n",
    "        data= self.data\n",
    "        threshold= self.threshold\n",
    "        imputation= pd.read_excel(path)\n",
    "        imputation.drop(['LEGEND'], axis= 1, inplace= True)\n",
    "        data= data[imputation['Feature name'].to_list()]\n",
    "        for name in data.columns.to_list():\n",
    "            if imputation[imputation['Feature name']== name]['IMPUTE NULLS'][imputation[imputation['Feature name']== name].index[0]]== 'YES':\n",
    "                value= imputation[imputation['Feature name']== name]['METHOD'][imputation[imputation['Feature name']== name].index[0]]\n",
    "                data[name].fillna(value, inplace= True)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T08:48:29.548276Z",
     "start_time": "2021-05-24T08:48:29.531321Z"
    },
    "code_folding": [
     5,
     44,
     66,
     90,
     96,
     104
    ]
   },
   "outputs": [],
   "source": [
    "class Explorer(object):\n",
    "    ## figure out how to auto import or autoinstall packages that are needed\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def completeness(self):\n",
    "        df = self.data.copy()\n",
    "        score = 100 - df.isnull().sum().sum() / (df.size) * 100\n",
    "        score = round(score)\n",
    "        if score <= 50:\n",
    "            color = 'darkred'\n",
    "            backrgound = 'red'\n",
    "        elif score in range(50, 80):\n",
    "            color = 'orange'\n",
    "            backrgound = 'orangered'\n",
    "        elif score >= 80:\n",
    "            color = 'rgb(112,130,56)'\n",
    "            backrgound = 'darkseagreen'\n",
    "        fig = go.Figure(\n",
    "            go.Indicator(mode=\"gauge+number\",\n",
    "                         value=score,\n",
    "                         domain={\n",
    "                             'x': [0, 1],\n",
    "                             'y': [0, 1]\n",
    "                         },\n",
    "                         title={'text': \"Data Completeness Score\"},\n",
    "                         gauge={\n",
    "                             'bar': {\n",
    "                                 'color': color\n",
    "                             },\n",
    "                             'axis': {\n",
    "                                 'range': [None, 100],\n",
    "                                 'tickwidth': 1,\n",
    "                                 'tickcolor': \"darkblue\"\n",
    "                             },\n",
    "                             'steps': [{\n",
    "                                 'range': [0, 100]\n",
    "                             }, {\n",
    "                                 'range': [0, 100],\n",
    "                                 'color': backrgound\n",
    "                             }]\n",
    "                         }))\n",
    "        return fig\n",
    "\n",
    "    def Missing_Data(self):\n",
    "        df = self.data\n",
    "        missing = df.isnull().sum() / df.shape[0] * 100\n",
    "        plt.subplots(figsize=(15, 7))\n",
    "        plt.title(\"Percentage of Missing Data\")\n",
    "        plot = missing.sort_values().plot(kind='bar')\n",
    "        plt.xlabel('Feature')\n",
    "        plt.ylabel(\"% of Missing Data\")\n",
    "        for p in plot.patches:\n",
    "            if p.get_height() == 0:\n",
    "                pass\n",
    "            else:\n",
    "                plot.annotate(format(p.get_height(), '.1f'),\n",
    "                              (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                              ha='center',\n",
    "                              va='center',\n",
    "                              color='white',\n",
    "                              xytext=(0, -12),\n",
    "                              rotation=90,\n",
    "                              textcoords='offset points')\n",
    "        return plt.show()\n",
    "    \n",
    "    def outliers_analysis(self):\n",
    "        df = self.data\n",
    "        IQR = df.quantile(0.75) - df.quantile(0.25)\n",
    "        return IQR\n",
    "    \n",
    "    def remove_outlier(self):\n",
    "        df = self.data\n",
    "        SKEW_BEFORE=[]\n",
    "        SKEW_AFTER=[]\n",
    "        FEATURES=[]\n",
    "        outliers= self.outliers_analysis()\n",
    "        columns = outliers.keys().to_list()\n",
    "        for col in columns:\n",
    "            FEATURES.append(col)\n",
    "            SKEW_BEFORE.append(df[col].skew())\n",
    "            lower = df[col].quantile(0.10)\n",
    "            upper = df[col].quantile(0.90)\n",
    "            ##Treating The Outliers\n",
    "            df[col]= np.where(df[col]<lower,lower,df[col])\n",
    "            df[col]= np.where(df[col]>upper,upper,df[col])\n",
    "            SKEW_AFTER.append(df[col].skew())\n",
    "        return pd.DataFrame({\"Feature\":FEATURES,\"skew_before\":SKEW_BEFORE,\"skew_after\":SKEW_AFTER})\n",
    "        \n",
    "        \n",
    "    def feature_removal(self):\n",
    "        df =self.data\n",
    "        for column in df.columns:\n",
    "            if df[column].isnull().sum()/len(df)>0.75:\n",
    "                df.drop(column,axis=1,inplace=True)\n",
    "    \n",
    "    def correlative(self):\n",
    "        ## NB: AUTO IMPORT SEABORN, MATPLOTLIB,PLOTLY'S GRAPH OBJECTS OR GIVE AN ERROR OUTPUT\n",
    "        df = self.data\n",
    "        corr = df.corr(method='spearman')\n",
    "        plt.subplots(figsize=(15,7))\n",
    "        sns.heatmap(corr, cmap='Greens')\n",
    "        return plt.show()\n",
    "    \n",
    "    def correlative_features(self):\n",
    "        data= self.data\n",
    "        correlated_features = set()\n",
    "        correlation_matrix = data.corr(method='spearman')\n",
    "        for i in range(len(correlation_matrix.columns)):\n",
    "            for j in range(i):\n",
    "                if abs(correlation_matrix.iloc[i, j])*100 > 60:\n",
    "                    colname = correlation_matrix.columns[i]\n",
    "                    correlated_features.add(colname)\n",
    "        return data[list(correlated_features)].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Z_LNy_CmKHM"
   },
   "source": [
    "### Data Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T08:48:31.447748Z",
     "start_time": "2021-05-24T08:48:31.440764Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def autoplot(df, feature,threshold=8):\n",
    "    plt.subplots(figsize=(14,7))\n",
    "    if df[feature].nunique()<=threshold:\n",
    "        plot =sns.countplot(x=feature,data=df)\n",
    "        for bar in plot.patches:\n",
    "            plot.annotate(round(bar.get_height()),(bar.get_x()+bar.get_width()/2,bar.get_height()), ha='center', va='center', size=15,xytext=(0,8),textcoords='offset points')\n",
    "    elif pd.api.types.is_float_dtype(df[feature].dtype):\n",
    "        sns.distplot(df[feature])\n",
    "        plt.title(f'Distribution for {feature}')\n",
    "        plt.xlabel('Bins')\n",
    "    elif pd.api.types.is_integer_dtype(df[feature].dtype):\n",
    "        sns.distplot(df[feature])\n",
    "        plt.title(f'distribution for for {feature}')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:36:23.652969Z",
     "start_time": "2021-06-26T10:36:23.375633Z"
    },
    "code_folding": [
     23,
     31,
     98,
     128,
     161,
     163,
     168,
     204,
     206,
     243,
     244,
     258
    ]
   },
   "outputs": [],
   "source": [
    "class AutoClassifier:\n",
    "    \"\"\"\n",
    "    This module helps in fitting to all the classification algorithms that are available in Scikit-learn\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : int, optional (default=0)\n",
    "        For the liblinear and lbfgs solvers set verbose to any positive\n",
    "        number for verbosity.\n",
    "    ignore_warnings : bool, optional (default=True)\n",
    "        When set to True, the warning related to algorigms that are not able to run are ignored.\n",
    "    Examples\n",
    "    --------\n",
    "    \"\"\"\n",
    "    ###NOTES:\n",
    "    ## Add an arguement for stratified train test split\n",
    "    ## Add an arguement for the test size while keeping the default at 30%\n",
    "    ## add a threshold for sampling the data if the data is large\n",
    "    ## add an stratification arguement\n",
    "    ## Side note>> Cross validation might also be useful\n",
    "    ## Bring Back top number: default is 5 and their validation scores.\n",
    "    ## Add a sampling arguement for when the data is too large\n",
    "    ## Add a balanced arguement for data... Boolean\n",
    "    \n",
    "    def __init__(self,data,Target:str, stratified=True,test_split=0.3,ignore_warnings=True,verbose=0):\n",
    "        self.data =data\n",
    "        self.Target =Target\n",
    "        self.stratified =stratified\n",
    "        self.test_split= test_split\n",
    "        self.ignore_warnings = ignore_warnings\n",
    "        self.verbose =verbose\n",
    "        \n",
    "    def classifer_load(self):\n",
    "        \n",
    "        try:\n",
    "            from sklearn.utils import all_estimators\n",
    "            from sklearn.base import ClassifierMixin\n",
    "            import sklearn\n",
    "        except:\n",
    "            print(\"please install sklearn Library To continue\")\n",
    "        #Loading all classifiers from Sklearn\n",
    "        CLASSIFIERS = [est for est in all_estimators() if issubclass(est[1], ClassifierMixin)]\n",
    "        \n",
    "        try:\n",
    "            from lightgbm import LGBMClassifier\n",
    "        except:\n",
    "            print(\"you need install lightgbm to continue\")\n",
    "        \n",
    "        CLASSIFIERS.append(('LGBMClassifier',LGBMClassifier))\n",
    "        \n",
    "        try:\n",
    "            from xgboost import XGBClassifier\n",
    "        except:\n",
    "            print(\"you need to install XGboost to continue\")\n",
    "        \n",
    "        CLASSIFIERS.append(('XGBClassifier',XGBClassifier))\n",
    "        \n",
    "        ##Removing the Gaussian Process Classifier\n",
    "        CLASSIFIERS.pop(CLASSIFIERS.index(('GaussianProcessClassifier',sklearn.gaussian_process.GaussianProcessClassifier)))\n",
    "        CLASSIFIERS.pop(CLASSIFIERS.index(('ClassifierChain',sklearn.multioutput.ClassifierChain)))\n",
    "        CLASSIFIERS.pop(CLASSIFIERS.index(('MultiOutputClassifier',sklearn.multioutput.MultiOutputClassifier)))\n",
    "        CLASSIFIERS.pop(CLASSIFIERS.index(('OneVsOneClassifier',sklearn.multiclass.OneVsOneClassifier)))\n",
    "        CLASSIFIERS.pop(CLASSIFIERS.index(('OneVsRestClassifier',sklearn.multiclass.OneVsRestClassifier)))\n",
    "        CLASSIFIERS.pop(CLASSIFIERS.index(('OutputCodeClassifier',sklearn.multiclass.OutputCodeClassifier)))\n",
    "        CLASSIFIERS.pop(CLASSIFIERS.index(('StackingClassifier',sklearn.ensemble.StackingClassifier)))\n",
    "        CLASSIFIERS.pop(CLASSIFIERS.index(('VotingClassifier',sklearn.ensemble.VotingClassifier)))\n",
    "        \n",
    "        \n",
    "        return CLASSIFIERS\n",
    "    \n",
    "    def datasplit(self):\n",
    "        df = self.data\n",
    "        if df.shape[0]> 100000:\n",
    "            \n",
    "            df = df.sample(n=100000)\n",
    "            \n",
    "            X = df.drop(self.Target,axis=1)\n",
    "            y=df[self.Target]\n",
    "            \n",
    "            return X,y\n",
    "        else:\n",
    "            \n",
    "            X = df.drop(self.Target,axis=1)\n",
    "            y=df[self.Target]\n",
    "            \n",
    "            return X,y\n",
    "    \n",
    "    def train_split(self):\n",
    "        X, y = self.datasplit()\n",
    "        try:\n",
    "            from sklearn.model_selection import train_test_split\n",
    "        except:\n",
    "            print(\"you need to install sklearn to continue\")\n",
    "        \n",
    "        if self.stratified==True:\n",
    "            return train_test_split(X, y, test_size=self.test_split,stratify=y, random_state=101)\n",
    "        else:\n",
    "            return train_test_split(X, y, test_size=self.test_split, random_state=101)\n",
    "\n",
    "    def numeric_transformer(self):\n",
    "        try:\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            from sklearn.pipeline import Pipeline\n",
    "            from sklearn.impute import SimpleImputer\n",
    "        except:\n",
    "            print(\"you need to install sklearn to continue\")\n",
    "        \n",
    "        return Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),('scaler', StandardScaler())])\n",
    "    \n",
    "    def categorical_transformer(self):\n",
    "        try:\n",
    "            from sklearn.preprocessing import OneHotEncoder\n",
    "            from sklearn.pipeline import Pipeline\n",
    "            from sklearn.impute import SimpleImputer\n",
    "        except:\n",
    "            print(\"you need to install sklearn\")\n",
    "            \n",
    "        return Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('encoding', OneHotEncoder(handle_unknown='ignore', sparse=False))])\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        try:\n",
    "            import numpy as np\n",
    "            import pandas as pd\n",
    "            from sklearn.metrics import accuracy_score, balanced_accuracy_score, fbeta_score, f1_score, roc_auc_score\n",
    "            from tqdm import tqdm\n",
    "            import logging as log\n",
    "            import warnings\n",
    "            warnings.filterwarnings('ignore')\n",
    "        except:\n",
    "            print(\"You have to install numpy and pandas to continue\")\n",
    "            \n",
    "        ACCURACY = []\n",
    "        BALANCED_ACCURACY = []\n",
    "        ROC_AUC = []\n",
    "        GINI=[]\n",
    "        F1 = []\n",
    "        FBETA =[]\n",
    "        LOG_LOSS=[]\n",
    "        names = []\n",
    "        \n",
    "        X_train, X_test, y_train, y_test =self.train_split()\n",
    "        \n",
    "        if type(X_train) is np.ndarray:\n",
    "            X_train = pd.DataFrame(X_train)\n",
    "            X_test = pd.DataFrame(X_test)\n",
    "            \n",
    "        numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "        categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "        try:\n",
    "            from sklearn.compose import ColumnTransformer\n",
    "        except:\n",
    "            print(\"you need to install sklearn to move forward\")\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('numeric', self.numeric_transformer(), numeric_features),\n",
    "                ('categorical', self.categorical_transformer(), categorical_features)\n",
    "            ])\n",
    "        classifers = self.classifer_load()\n",
    "        \n",
    "        for name, model in tqdm(classifers):\n",
    "            try:\n",
    "                try:\n",
    "                    from sklearn.pipeline import Pipeline\n",
    "                except:\n",
    "                    print(\"you need to install sklearn to continue\")\n",
    "                \n",
    "                \n",
    "                pipe = Pipeline(steps=[('preprocessor', preprocessor),('classifier', model())])\n",
    "                if (name ==\"CategoricalNB\") or (name==\"ComplementNB\") or (name==\"MultinomialNB\"):\n",
    "                    pipe.fit(abs(X_train),y_train)\n",
    "                    \n",
    "                    y_pred = pipe.predict(X_test)\n",
    "                    \n",
    "                    accuracy = accuracy_score(y_test, y_pred, normalize=True)\n",
    "                    \n",
    "                    b_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "                    \n",
    "                    fbeta = fbeta_score(y_test,y_pred,beta=0.5)\n",
    "                    \n",
    "                    try:\n",
    "                        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "                        \n",
    "                    except Exception as exception:\n",
    "                        roc_auc = None\n",
    "                        if self.ignore_warnings == False:\n",
    "                            print(\"ROC AUC couldn't be calculated for \"+name)\n",
    "                            print(exception)\n",
    "                    try:\n",
    "                        gini = (2*roc_auc-1)*100\n",
    "                    except Exception as exception:\n",
    "                        gini=None\n",
    "                        if self.ignore_warnings==False:\n",
    "                            print(\"GINI % couldn't be calcuated for\",name)\n",
    "                            print(exception)\n",
    "                    names.append(name)\n",
    "                    ACCURACY.append(accuracy)\n",
    "                    BALANCED_ACCURACY.append(b_accuracy)\n",
    "                    ROC_AUC.append(roc_auc)\n",
    "                    GINI.append(gini)\n",
    "                    F1.append(f1)\n",
    "                    FBETA.append(fbeta)\n",
    "                    \n",
    "                    if self.verbose > 0:\n",
    "                        print({\"Model\": name,\"Accuracy\": accuracy,\"Balanced Accuracy\": b_accuracy,\"F Beta\": fbeta,\"F1 Score\": f1,\"ROC AUC\": roc_auc,\"Gini Coefficient\":gini})\n",
    "                else:\n",
    "                    pipe.fit(X_train, y_train)\n",
    "                    \n",
    "                    y_pred = pipe.predict(X_test)\n",
    "                    \n",
    "                    accuracy = accuracy_score(y_test, y_pred, normalize=True)\n",
    "                    \n",
    "                    b_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "                    \n",
    "                    fbeta = fbeta_score(y_test,y_pred,beta=0.5)\n",
    "                    try:\n",
    "                        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "                        \n",
    "                    except Exception as exception:\n",
    "                        roc_auc = None\n",
    "                        if self.ignore_warnings == False:\n",
    "                            print(\"ROC AUC couldn't be calculated for \"+name)\n",
    "                            print(exception)\n",
    "                    try:\n",
    "                        gini = (2*roc_auc-1)*100\n",
    "                    except Exception as exception:\n",
    "                        gini=None\n",
    "                        if self.ignore_warnings==False:\n",
    "                            print(\"GINI % couldn't be calcuated for\",name)\n",
    "                            print(exception)\n",
    "                    names.append(name)\n",
    "                    ACCURACY.append(accuracy)\n",
    "                    BALANCED_ACCURACY.append(b_accuracy)\n",
    "                    ROC_AUC.append(roc_auc)\n",
    "                    GINI.append(gini)\n",
    "                    F1.append(f1)\n",
    "                    FBETA.append(fbeta)\n",
    "                    \n",
    "                    if self.verbose > 0:\n",
    "                        print({\"Model\": name,\"Accuracy\": accuracy,\"Balanced Accuracy\": b_accuracy,\"F Beta\": fbeta,\"F1 Score\": f1,\"ROC AUC\": roc_auc,\"Gini Coefficient\":gini})\n",
    "            except Exception as exception:\n",
    "                if self.ignore_warnings == False:\n",
    "                    print(name + \" model failed to execute\")\n",
    "                    print(exception)\n",
    "        scores = pd.DataFrame({\"Model\": names,\n",
    "                               \"Accuracy\": ACCURACY,\n",
    "                               \"Balanced Accuracy\": BALANCED_ACCURACY,\n",
    "                               \"F1 Score\": F1,\n",
    "                               \"F Beta\":FBETA,\n",
    "                               \"ROC AUC\": ROC_AUC,\n",
    "                               \"GINI Coefficient\":GINI})\n",
    "        scores = scores.sort_values(\n",
    "            by=['Accuracy','GINI Coefficient'], ascending=False).set_index('Model')\n",
    "        return scores\n",
    "    \n",
    "    def cross_validation(self):\n",
    "        return \"Coming Sooon.....\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:33:09.476744Z",
     "start_time": "2021-06-26T10:33:09.400965Z"
    }
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"wine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:33:10.765427Z",
     "start_time": "2021-06-26T10:33:10.676676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol quality  \n",
       "0      9.4     bad  \n",
       "1      9.8     bad  \n",
       "2      9.8     bad  \n",
       "3      9.8    good  \n",
       "4      9.4     bad  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:33:11.829594Z",
     "start_time": "2021-06-26T10:33:11.758333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        0  \n",
       "1      9.8        0  \n",
       "2      9.8        0  \n",
       "3      9.8        1  \n",
       "4      9.4        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['quality'].replace('bad',0,inplace=True)\n",
    "train['quality'].replace('good',1,inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:33:12.596184Z",
     "start_time": "2021-06-26T10:33:12.583503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:36:28.739997Z",
     "start_time": "2021-06-26T10:36:28.735563Z"
    }
   },
   "outputs": [],
   "source": [
    "model= AutoClassifier(data=train,Target='quality', test_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:36:41.116707Z",
     "start_time": "2021-06-26T10:36:30.670700Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [00:10<00:00,  3.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F Beta</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>GINI Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.85625</td>\n",
       "      <td>0.854965</td>\n",
       "      <td>0.856177</td>\n",
       "      <td>0.864055</td>\n",
       "      <td>0.854965</td>\n",
       "      <td>70.993086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.840509</td>\n",
       "      <td>0.843225</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.840509</td>\n",
       "      <td>68.101823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier</th>\n",
       "      <td>0.81875</td>\n",
       "      <td>0.816310</td>\n",
       "      <td>0.818429</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.816310</td>\n",
       "      <td>63.262099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.805625</td>\n",
       "      <td>0.806334</td>\n",
       "      <td>0.821596</td>\n",
       "      <td>0.805625</td>\n",
       "      <td>61.125079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.804683</td>\n",
       "      <td>0.806151</td>\n",
       "      <td>0.817972</td>\n",
       "      <td>0.804683</td>\n",
       "      <td>60.936518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.799811</td>\n",
       "      <td>0.800157</td>\n",
       "      <td>0.817536</td>\n",
       "      <td>0.799811</td>\n",
       "      <td>59.962288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.782370</td>\n",
       "      <td>0.781550</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.782370</td>\n",
       "      <td>56.473916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.780484</td>\n",
       "      <td>0.781344</td>\n",
       "      <td>0.798122</td>\n",
       "      <td>0.780484</td>\n",
       "      <td>56.096794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.780484</td>\n",
       "      <td>0.781344</td>\n",
       "      <td>0.798122</td>\n",
       "      <td>0.780484</td>\n",
       "      <td>56.096794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.779541</td>\n",
       "      <td>0.781138</td>\n",
       "      <td>0.794931</td>\n",
       "      <td>0.779541</td>\n",
       "      <td>55.908234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.77500</td>\n",
       "      <td>0.773727</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.773727</td>\n",
       "      <td>54.745443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.76875</td>\n",
       "      <td>0.768856</td>\n",
       "      <td>0.768995</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.768856</td>\n",
       "      <td>53.771213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.76875</td>\n",
       "      <td>0.766970</td>\n",
       "      <td>0.768632</td>\n",
       "      <td>0.783410</td>\n",
       "      <td>0.766970</td>\n",
       "      <td>53.394092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.76875</td>\n",
       "      <td>0.766028</td>\n",
       "      <td>0.768340</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.766028</td>\n",
       "      <td>53.205531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.76875</td>\n",
       "      <td>0.766028</td>\n",
       "      <td>0.768340</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.766028</td>\n",
       "      <td>53.205531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.76875</td>\n",
       "      <td>0.766028</td>\n",
       "      <td>0.768340</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.766028</td>\n",
       "      <td>53.205531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.76875</td>\n",
       "      <td>0.765085</td>\n",
       "      <td>0.767973</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.765085</td>\n",
       "      <td>53.016970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.76875</td>\n",
       "      <td>0.763199</td>\n",
       "      <td>0.767013</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.763199</td>\n",
       "      <td>52.639849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.761157</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.761157</td>\n",
       "      <td>52.231301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.760214</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>0.760214</td>\n",
       "      <td>52.042740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.760214</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>0.760214</td>\n",
       "      <td>52.042740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.760214</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>0.760214</td>\n",
       "      <td>52.042740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.760214</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>0.760214</td>\n",
       "      <td>52.042740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.759271</td>\n",
       "      <td>0.761900</td>\n",
       "      <td>0.773543</td>\n",
       "      <td>0.759271</td>\n",
       "      <td>51.854180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.754400</td>\n",
       "      <td>0.756125</td>\n",
       "      <td>0.771889</td>\n",
       "      <td>0.754400</td>\n",
       "      <td>50.879950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.728473</td>\n",
       "      <td>0.732761</td>\n",
       "      <td>0.738866</td>\n",
       "      <td>0.728473</td>\n",
       "      <td>45.694532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.73125</td>\n",
       "      <td>0.735858</td>\n",
       "      <td>0.731114</td>\n",
       "      <td>0.767196</td>\n",
       "      <td>0.735858</td>\n",
       "      <td>47.171590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.73125</td>\n",
       "      <td>0.729258</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.748848</td>\n",
       "      <td>0.729258</td>\n",
       "      <td>45.851666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.70000</td>\n",
       "      <td>0.702074</td>\n",
       "      <td>0.700375</td>\n",
       "      <td>0.728643</td>\n",
       "      <td>0.702074</td>\n",
       "      <td>40.414833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.60625</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>0.602277</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>19.767442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.53750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375813</td>\n",
       "      <td>0.592287</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Accuracy  Balanced Accuracy  F1 Score  \\\n",
       "Model                                                                   \n",
       "ExtraTreesClassifier             0.85625           0.854965  0.856177   \n",
       "XGBClassifier                    0.84375           0.840509  0.843225   \n",
       "HistGradientBoostingClassifier   0.81875           0.816310  0.818429   \n",
       "RandomForestClassifier           0.80625           0.805625  0.806334   \n",
       "LGBMClassifier                   0.80625           0.804683  0.806151   \n",
       "NuSVC                            0.80000           0.799811  0.800157   \n",
       "BaggingClassifier                0.78125           0.782370  0.781550   \n",
       "LabelPropagation                 0.78125           0.780484  0.781344   \n",
       "LabelSpreading                   0.78125           0.780484  0.781344   \n",
       "SVC                              0.78125           0.779541  0.781138   \n",
       "ExtraTreeClassifier              0.77500           0.773727  0.775000   \n",
       "GaussianNB                       0.76875           0.768856  0.768995   \n",
       "GradientBoostingClassifier       0.76875           0.766970  0.768632   \n",
       "CalibratedClassifierCV           0.76875           0.766028  0.768340   \n",
       "LinearSVC                        0.76875           0.766028  0.768340   \n",
       "LogisticRegression               0.76875           0.766028  0.768340   \n",
       "AdaBoostClassifier               0.76875           0.765085  0.767973   \n",
       "QuadraticDiscriminantAnalysis    0.76875           0.763199  0.767013   \n",
       "MLPClassifier                    0.76250           0.761157  0.762500   \n",
       "LinearDiscriminantAnalysis       0.76250           0.760214  0.762238   \n",
       "LogisticRegressionCV             0.76250           0.760214  0.762238   \n",
       "RidgeClassifier                  0.76250           0.760214  0.762238   \n",
       "RidgeClassifierCV                0.76250           0.760214  0.762238   \n",
       "Perceptron                       0.76250           0.759271  0.761900   \n",
       "DecisionTreeClassifier           0.75625           0.754400  0.756125   \n",
       "KNeighborsClassifier             0.73750           0.728473  0.732761   \n",
       "NearestCentroid                  0.73125           0.735858  0.731114   \n",
       "BernoulliNB                      0.73125           0.729258  0.731113   \n",
       "SGDClassifier                    0.70000           0.702074  0.700375   \n",
       "PassiveAggressiveClassifier      0.60625           0.598837  0.602277   \n",
       "DummyClassifier                  0.53750           0.500000  0.375813   \n",
       "\n",
       "                                  F Beta   ROC AUC  GINI Coefficient  \n",
       "Model                                                                 \n",
       "ExtraTreesClassifier            0.864055  0.854965         70.993086  \n",
       "XGBClassifier                   0.844444  0.840509         68.101823  \n",
       "HistGradientBoostingClassifier  0.825792  0.816310         63.262099  \n",
       "RandomForestClassifier          0.821596  0.805625         61.125079  \n",
       "LGBMClassifier                  0.817972  0.804683         60.936518  \n",
       "NuSVC                           0.817536  0.799811         59.962288  \n",
       "BaggingClassifier               0.804878  0.782370         56.473916  \n",
       "LabelPropagation                0.798122  0.780484         56.096794  \n",
       "LabelSpreading                  0.798122  0.780484         56.096794  \n",
       "SVC                             0.794931  0.779541         55.908234  \n",
       "ExtraTreeClassifier             0.790698  0.773727         54.745443  \n",
       "GaussianNB                      0.789474  0.768856         53.771213  \n",
       "GradientBoostingClassifier      0.783410  0.766970         53.394092  \n",
       "CalibratedClassifierCV          0.780543  0.766028         53.205531  \n",
       "LinearSVC                       0.780543  0.766028         53.205531  \n",
       "LogisticRegression              0.780543  0.766028         53.205531  \n",
       "AdaBoostClassifier              0.777778  0.765085         53.016970  \n",
       "QuadraticDiscriminantAnalysis   0.772532  0.763199         52.639849  \n",
       "MLPClassifier                   0.779070  0.761157         52.231301  \n",
       "LinearDiscriminantAnalysis      0.776256  0.760214         52.042740  \n",
       "LogisticRegressionCV            0.776256  0.760214         52.042740  \n",
       "RidgeClassifier                 0.776256  0.760214         52.042740  \n",
       "RidgeClassifierCV               0.776256  0.760214         52.042740  \n",
       "Perceptron                      0.773543  0.759271         51.854180  \n",
       "DecisionTreeClassifier          0.771889  0.754400         50.879950  \n",
       "KNeighborsClassifier            0.738866  0.728473         45.694532  \n",
       "NearestCentroid                 0.767196  0.735858         47.171590  \n",
       "BernoulliNB                     0.748848  0.729258         45.851666  \n",
       "SGDClassifier                   0.728643  0.702074         40.414833  \n",
       "PassiveAggressiveClassifier     0.632911  0.598837         19.767442  \n",
       "DummyClassifier                 0.592287  0.500000          0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T15:27:26.944940Z",
     "start_time": "2021-06-25T15:27:26.929817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coming Sooon.....'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cross_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:39:21.354053Z",
     "start_time": "2021-06-26T10:39:19.806877Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:39:21.455082Z",
     "start_time": "2021-06-26T10:39:21.358158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 41)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=10000)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:39:22.352439Z",
     "start_time": "2021-06-26T10:39:22.294904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    78.92\n",
       "1    21.08\n",
       "Name: loan_default, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loan_default.value_counts()/len(df) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T10:39:38.690364Z",
     "start_time": "2021-06-26T10:39:38.686191Z"
    }
   },
   "outputs": [],
   "source": [
    "modeller = AutoClassifier(data=df, Target='loan_default',test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T11:15:14.888689Z",
     "start_time": "2021-06-26T10:39:39.333148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 35/35 [35:35<00:00, 61.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F Beta</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>GINI Coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.7890</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.701464</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>1.041573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.7890</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.695943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.7890</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.695943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.7890</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.695943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <td>0.7885</td>\n",
       "      <td>0.499683</td>\n",
       "      <td>0.695696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499683</td>\n",
       "      <td>-0.063371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.7880</td>\n",
       "      <td>0.501102</td>\n",
       "      <td>0.697317</td>\n",
       "      <td>0.022422</td>\n",
       "      <td>0.501102</td>\n",
       "      <td>0.220448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.504257</td>\n",
       "      <td>0.700681</td>\n",
       "      <td>0.062241</td>\n",
       "      <td>0.504257</td>\n",
       "      <td>0.851459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.499917</td>\n",
       "      <td>0.696139</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.499917</td>\n",
       "      <td>-0.016519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.7870</td>\n",
       "      <td>0.508280</td>\n",
       "      <td>0.704735</td>\n",
       "      <td>0.104563</td>\n",
       "      <td>0.508280</td>\n",
       "      <td>1.656065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.7855</td>\n",
       "      <td>0.499518</td>\n",
       "      <td>0.696057</td>\n",
       "      <td>0.021459</td>\n",
       "      <td>0.499518</td>\n",
       "      <td>-0.096409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingClassifier</th>\n",
       "      <td>0.7830</td>\n",
       "      <td>0.514425</td>\n",
       "      <td>0.710448</td>\n",
       "      <td>0.164577</td>\n",
       "      <td>0.514425</td>\n",
       "      <td>2.885049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.7830</td>\n",
       "      <td>0.504877</td>\n",
       "      <td>0.701728</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.504877</td>\n",
       "      <td>0.975498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.7815</td>\n",
       "      <td>0.503059</td>\n",
       "      <td>0.700085</td>\n",
       "      <td>0.081227</td>\n",
       "      <td>0.503059</td>\n",
       "      <td>0.611789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.506448</td>\n",
       "      <td>0.703334</td>\n",
       "      <td>0.115512</td>\n",
       "      <td>0.506448</td>\n",
       "      <td>1.289652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.526563</td>\n",
       "      <td>0.719489</td>\n",
       "      <td>0.236077</td>\n",
       "      <td>0.526563</td>\n",
       "      <td>5.312682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.7565</td>\n",
       "      <td>0.503708</td>\n",
       "      <td>0.699611</td>\n",
       "      <td>0.154525</td>\n",
       "      <td>0.503708</td>\n",
       "      <td>0.741535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.7490</td>\n",
       "      <td>0.517182</td>\n",
       "      <td>0.706970</td>\n",
       "      <td>0.216049</td>\n",
       "      <td>0.517182</td>\n",
       "      <td>3.436469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.502344</td>\n",
       "      <td>0.697190</td>\n",
       "      <td>0.162083</td>\n",
       "      <td>0.502344</td>\n",
       "      <td>0.468828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.7470</td>\n",
       "      <td>0.492480</td>\n",
       "      <td>0.690160</td>\n",
       "      <td>0.117773</td>\n",
       "      <td>0.492480</td>\n",
       "      <td>-1.504094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.7435</td>\n",
       "      <td>0.520641</td>\n",
       "      <td>0.707365</td>\n",
       "      <td>0.229469</td>\n",
       "      <td>0.520641</td>\n",
       "      <td>4.128148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.513201</td>\n",
       "      <td>0.700482</td>\n",
       "      <td>0.211864</td>\n",
       "      <td>0.513201</td>\n",
       "      <td>2.640273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.513960</td>\n",
       "      <td>0.696612</td>\n",
       "      <td>0.219892</td>\n",
       "      <td>0.513960</td>\n",
       "      <td>2.791944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.7155</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.707115</td>\n",
       "      <td>0.286710</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>9.259126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.7010</td>\n",
       "      <td>0.507596</td>\n",
       "      <td>0.685497</td>\n",
       "      <td>0.213450</td>\n",
       "      <td>0.507596</td>\n",
       "      <td>1.519111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.6995</td>\n",
       "      <td>0.541364</td>\n",
       "      <td>0.697216</td>\n",
       "      <td>0.276690</td>\n",
       "      <td>0.541364</td>\n",
       "      <td>8.272815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.6890</td>\n",
       "      <td>0.511275</td>\n",
       "      <td>0.681633</td>\n",
       "      <td>0.225131</td>\n",
       "      <td>0.511275</td>\n",
       "      <td>2.254939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.6715</td>\n",
       "      <td>0.520148</td>\n",
       "      <td>0.675690</td>\n",
       "      <td>0.243957</td>\n",
       "      <td>0.520148</td>\n",
       "      <td>4.029637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.6710</td>\n",
       "      <td>0.520699</td>\n",
       "      <td>0.675579</td>\n",
       "      <td>0.244880</td>\n",
       "      <td>0.520699</td>\n",
       "      <td>4.139861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.5790</td>\n",
       "      <td>0.570895</td>\n",
       "      <td>0.617437</td>\n",
       "      <td>0.295078</td>\n",
       "      <td>0.570895</td>\n",
       "      <td>14.178966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.3585</td>\n",
       "      <td>0.513619</td>\n",
       "      <td>0.368555</td>\n",
       "      <td>0.253612</td>\n",
       "      <td>0.513619</td>\n",
       "      <td>2.723767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Accuracy  Balanced Accuracy  F1 Score  \\\n",
       "Model                                                                   \n",
       "BernoulliNB                       0.7890           0.505208  0.701464   \n",
       "CalibratedClassifierCV            0.7890           0.500000  0.695943   \n",
       "DummyClassifier                   0.7890           0.500000  0.695943   \n",
       "SVC                               0.7890           0.500000  0.695943   \n",
       "LogisticRegressionCV              0.7885           0.499683  0.695696   \n",
       "RandomForestClassifier            0.7880           0.501102  0.697317   \n",
       "ExtraTreesClassifier              0.7875           0.504257  0.700681   \n",
       "GradientBoostingClassifier        0.7875           0.499917  0.696139   \n",
       "AdaBoostClassifier                0.7870           0.508280  0.704735   \n",
       "RidgeClassifierCV                 0.7855           0.499518  0.696057   \n",
       "HistGradientBoostingClassifier    0.7830           0.514425  0.710448   \n",
       "BaggingClassifier                 0.7830           0.504877  0.701728   \n",
       "LogisticRegression                0.7815           0.503059  0.700085   \n",
       "LGBMClassifier                    0.7800           0.506448  0.703334   \n",
       "XGBClassifier                     0.7775           0.526563  0.719489   \n",
       "RidgeClassifier                   0.7565           0.503708  0.699611   \n",
       "KNeighborsClassifier              0.7490           0.517182  0.706970   \n",
       "LinearSVC                         0.7475           0.502344  0.697190   \n",
       "QuadraticDiscriminantAnalysis     0.7470           0.492480  0.690160   \n",
       "SGDClassifier                     0.7435           0.520641  0.707365   \n",
       "LinearDiscriminantAnalysis        0.7345           0.513201  0.700482   \n",
       "PassiveAggressiveClassifier       0.7220           0.513960  0.696612   \n",
       "Perceptron                        0.7155           0.546296  0.707115   \n",
       "ExtraTreeClassifier               0.7010           0.507596  0.685497   \n",
       "MLPClassifier                     0.6995           0.541364  0.697216   \n",
       "DecisionTreeClassifier            0.6890           0.511275  0.681633   \n",
       "LabelSpreading                    0.6715           0.520148  0.675690   \n",
       "LabelPropagation                  0.6710           0.520699  0.675579   \n",
       "NearestCentroid                   0.5790           0.570895  0.617437   \n",
       "GaussianNB                        0.3585           0.513619  0.368555   \n",
       "\n",
       "                                  F Beta   ROC AUC  GINI Coefficient  \n",
       "Model                                                                 \n",
       "BernoulliNB                     0.063830  0.505208          1.041573  \n",
       "CalibratedClassifierCV          0.000000  0.500000          0.000000  \n",
       "DummyClassifier                 0.000000  0.500000          0.000000  \n",
       "SVC                             0.000000  0.500000          0.000000  \n",
       "LogisticRegressionCV            0.000000  0.499683         -0.063371  \n",
       "RandomForestClassifier          0.022422  0.501102          0.220448  \n",
       "ExtraTreesClassifier            0.062241  0.504257          0.851459  \n",
       "GradientBoostingClassifier      0.011312  0.499917         -0.016519  \n",
       "AdaBoostClassifier              0.104563  0.508280          1.656065  \n",
       "RidgeClassifierCV               0.021459  0.499518         -0.096409  \n",
       "HistGradientBoostingClassifier  0.164577  0.514425          2.885049  \n",
       "BaggingClassifier               0.090909  0.504877          0.975498  \n",
       "LogisticRegression              0.081227  0.503059          0.611789  \n",
       "LGBMClassifier                  0.115512  0.506448          1.289652  \n",
       "XGBClassifier                   0.236077  0.526563          5.312682  \n",
       "RidgeClassifier                 0.154525  0.503708          0.741535  \n",
       "KNeighborsClassifier            0.216049  0.517182          3.436469  \n",
       "LinearSVC                       0.162083  0.502344          0.468828  \n",
       "QuadraticDiscriminantAnalysis   0.117773  0.492480         -1.504094  \n",
       "SGDClassifier                   0.229469  0.520641          4.128148  \n",
       "LinearDiscriminantAnalysis      0.211864  0.513201          2.640273  \n",
       "PassiveAggressiveClassifier     0.219892  0.513960          2.791944  \n",
       "Perceptron                      0.286710  0.546296          9.259126  \n",
       "ExtraTreeClassifier             0.213450  0.507596          1.519111  \n",
       "MLPClassifier                   0.276690  0.541364          8.272815  \n",
       "DecisionTreeClassifier          0.225131  0.511275          2.254939  \n",
       "LabelSpreading                  0.243957  0.520148          4.029637  \n",
       "LabelPropagation                0.244880  0.520699          4.139861  \n",
       "NearestCentroid                 0.295078  0.570895         14.178966  \n",
       "GaussianNB                      0.253612  0.513619          2.723767  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeller.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    This module mitigates the issue of class imbalance in the target variable using\n",
    "    Synthetic Minority Oversampling Technique (SMOTE)\n",
    "    \n",
    "    Important Note : Please make sure the target variable is the last column in the data frame.\n",
    "    \n",
    "    ----------\n",
    "    input  : Pandas DataFrame with imbalanced target variable\n",
    "    \n",
    "    ----------\n",
    "    output : Pandas DataFrame with balanced target variable\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Dependencies\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    try:\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "    except:\n",
    "        print(\"You need sklearn to continue. Install now?(y/n)\")\n",
    "        response = input()\n",
    "        if response == 'y':\n",
    "            !pip install --user sklearn\n",
    "        else:\n",
    "            print(\"please install sklearn library To continue\")\n",
    "    \n",
    "    try:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "    except:\n",
    "        print(\"You need imblearn to continue. Install now?(y/n)\")\n",
    "        response = input()\n",
    "        if response == 'y':\n",
    "            !pip install --user imblearn\n",
    "        else:\n",
    "            print(\"please install imblearn library To continue\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    # split into input and output elements\n",
    "    X, y = df.iloc[:, :-1], df.iloc[:, -1:]\n",
    "    # label encode the target variable\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    # transform the dataset\n",
    "    SMOTE = SMOTE()\n",
    "    X, y = SMOTE.fit_resample(X, y)\n",
    "    df = X\n",
    "    df['Target'] = y\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = pd.read_csv('glass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fcad158388>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "glass['Type'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = class_balance(glass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fcaf211ac8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df['Target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AutoLearn Machine learning Platform",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
